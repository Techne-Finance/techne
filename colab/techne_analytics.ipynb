{
    "nbformat": 4,
    "nbformat_minor": 0,
    "metadata": {
        "colab": {
            "provenance": [],
            "toc_visible": true
        },
        "kernelspec": {
            "name": "python3",
            "display_name": "Python 3"
        }
    },
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# ðŸ§ª Techne Finance - Analytics Laboratory\n",
                "\n",
                "**Purpose**: Heavy computations for your DeFi bot that VPS can't handle.\n",
                "\n",
                "## Modules:\n",
                "1. **APY Trend Analysis** - Linear regression to predict yield decay\n",
                "2. **Wash Trading Detection** - K-means clustering on swap patterns\n",
                "3. **Parking Threshold Optimization** - Monte Carlo backtesting\n",
                "\n",
                "---"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ==========================================\n",
                "# ðŸ”§ SETUP - Run this first!\n",
                "# ==========================================\n",
                "!pip install supabase pandas numpy scikit-learn requests -q\n",
                "\n",
                "import json\n",
                "import numpy as np\n",
                "import pandas as pd\n",
                "from datetime import datetime, timedelta\n",
                "from sklearn.linear_model import LinearRegression\n",
                "from sklearn.cluster import KMeans\n",
                "from supabase import create_client\n",
                "import requests\n",
                "\n",
                "# ðŸ“Œ YOUR CREDENTIALS (paste from .env)\n",
                "SUPABASE_URL = \"https://your-project.supabase.co\"  # @param {type:\"string\"}\n",
                "SUPABASE_KEY = \"your-anon-key\"  # @param {type:\"string\"}\n",
                "\n",
                "supabase = create_client(SUPABASE_URL, SUPABASE_KEY)\n",
                "print(\"âœ… Setup complete!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## ðŸ“ˆ Module 1: APY Trend Analysis\n",
                "\n",
                "Calculates the **slope** of APY over time using Linear Regression:\n",
                "- Positive slope = APY growing\n",
                "- Negative slope = APY decaying (danger!)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def analyze_apy_trend(pool_address: str, days: int = 30) -> dict:\n",
                "    \"\"\"\n",
                "    Fetch APY history from DefiLlama and calculate trend.\n",
                "    Returns JSON with slope, RÂ², and recommendation.\n",
                "    \"\"\"\n",
                "    # Fetch from DefiLlama API\n",
                "    url = f\"https://yields.llama.fi/chart/{pool_address}\"\n",
                "    response = requests.get(url)\n",
                "    \n",
                "    if response.status_code != 200:\n",
                "        return {\"error\": f\"Failed to fetch data: {response.status_code}\"}\n",
                "    \n",
                "    data = response.json().get(\"data\", [])\n",
                "    if len(data) < 7:\n",
                "        return {\"error\": \"Insufficient data points (need at least 7 days)\"}\n",
                "    \n",
                "    # Take last N days\n",
                "    recent = data[-days:] if len(data) >= days else data\n",
                "    \n",
                "    # Prepare for regression\n",
                "    df = pd.DataFrame(recent)\n",
                "    df['day_index'] = range(len(df))\n",
                "    \n",
                "    X = df['day_index'].values.reshape(-1, 1)\n",
                "    y = df['apy'].values\n",
                "    \n",
                "    # Linear Regression\n",
                "    model = LinearRegression()\n",
                "    model.fit(X, y)\n",
                "    \n",
                "    slope = model.coef_[0]  # APY change per day\n",
                "    r_squared = model.score(X, y)\n",
                "    current_apy = y[-1]\n",
                "    avg_apy = np.mean(y)\n",
                "    volatility = np.std(y)\n",
                "    \n",
                "    # Projected APY in 7 days\n",
                "    projected_7d = current_apy + (slope * 7)\n",
                "    \n",
                "    # Recommendation logic\n",
                "    if slope < -0.5 and r_squared > 0.6:\n",
                "        recommendation = \"AVOID - Strong decay trend\"\n",
                "    elif slope < -0.2:\n",
                "        recommendation = \"CAUTION - Mild decay\"\n",
                "    elif slope > 0.3:\n",
                "        recommendation = \"OPPORTUNITY - Growing yield\"\n",
                "    else:\n",
                "        recommendation = \"STABLE - Flat trend\"\n",
                "    \n",
                "    return {\n",
                "        \"pool_address\": pool_address,\n",
                "        \"analysis_date\": datetime.now().isoformat(),\n",
                "        \"days_analyzed\": len(recent),\n",
                "        \"current_apy\": round(current_apy, 2),\n",
                "        \"avg_apy\": round(avg_apy, 2),\n",
                "        \"volatility\": round(volatility, 2),\n",
                "        \"slope_per_day\": round(slope, 4),\n",
                "        \"r_squared\": round(r_squared, 4),\n",
                "        \"projected_apy_7d\": round(projected_7d, 2),\n",
                "        \"recommendation\": recommendation\n",
                "    }\n",
                "\n",
                "# ðŸ§ª TEST - Aerodrome WETH-USDC\n",
                "result = analyze_apy_trend(\"747c1d2a-c668-4682-b9f9-296708a3dd90\")\n",
                "print(json.dumps(result, indent=2))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## ðŸ” Module 2: Wash Trading Detection\n",
                "\n",
                "Uses **K-Means clustering** on wallet addresses to detect:\n",
                "- Concentration of volume in few wallets\n",
                "- Circular trading patterns\n",
                "\n",
                "**NOTE**: Uses Uniswap V3 Base subgraph (works for most AMMs)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def detect_wash_trading(pool_address: str) -> dict:\n",
                "    \"\"\"\n",
                "    Analyze swap patterns from The Graph to detect wash trading.\n",
                "    Returns wash trading probability (0-100%).\n",
                "    \n",
                "    Uses Uniswap V3 Base subgraph which has broad coverage.\n",
                "    \"\"\"\n",
                "    # Multiple subgraph options for Base\n",
                "    SUBGRAPHS = [\n",
                "        # Uniswap V3 on Base (most active)\n",
                "        \"https://api.studio.thegraph.com/query/48211/uniswap-v3-base/version/latest\",\n",
                "        # Backup: Aerodrome (corrected URL)\n",
                "        \"https://api.studio.thegraph.com/query/50472/aerodrome-slipstream/version/latest\"\n",
                "    ]\n",
                "    \n",
                "    # Query that works with standard Uniswap V3 schema\n",
                "    query = \"\"\"\n",
                "    query GetSwaps($pool: String!) {\n",
                "        swaps(first: 500, where: {pool: $pool}, orderBy: timestamp, orderDirection: desc) {\n",
                "            origin\n",
                "            sender\n",
                "            recipient\n",
                "            amountUSD\n",
                "            timestamp\n",
                "        }\n",
                "    }\n",
                "    \"\"\"\n",
                "    \n",
                "    swaps = []\n",
                "    for graph_url in SUBGRAPHS:\n",
                "        try:\n",
                "            response = requests.post(\n",
                "                graph_url,\n",
                "                json={\"query\": query, \"variables\": {\"pool\": pool_address.lower()}},\n",
                "                timeout=10\n",
                "            )\n",
                "            if response.status_code == 200:\n",
                "                data = response.json()\n",
                "                swaps = data.get(\"data\", {}).get(\"swaps\", [])\n",
                "                if len(swaps) >= 20:\n",
                "                    break\n",
                "        except:\n",
                "            continue\n",
                "    \n",
                "    if len(swaps) < 20:\n",
                "        return {\n",
                "            \"error\": f\"Insufficient swaps (found {len(swaps)}, need 20+)\",\n",
                "            \"swap_count\": len(swaps),\n",
                "            \"tip\": \"Try a more active pool like WETH-USDC on Uniswap V3\"\n",
                "        }\n",
                "    \n",
                "    df = pd.DataFrame(swaps)\n",
                "    df['amountUSD'] = pd.to_numeric(df['amountUSD'], errors='coerce').fillna(0)\n",
                "    \n",
                "    # Use 'origin' or 'sender' depending on what's available\n",
                "    wallet_col = 'origin' if 'origin' in df.columns and df['origin'].notna().any() else 'sender'\n",
                "    \n",
                "    # === METRIC 1: Wallet Concentration ===\n",
                "    wallet_volumes = df.groupby(wallet_col)['amountUSD'].sum()\n",
                "    total_volume = wallet_volumes.sum()\n",
                "    if total_volume > 0:\n",
                "        top_3_concentration = wallet_volumes.nlargest(3).sum() / total_volume * 100\n",
                "    else:\n",
                "        top_3_concentration = 0\n",
                "    \n",
                "    # === METRIC 2: Unique Wallets Ratio ===\n",
                "    unique_wallets = df[wallet_col].nunique()\n",
                "    wallet_ratio = unique_wallets / len(swaps) * 100\n",
                "    \n",
                "    # === METRIC 3: Circular Trading ===\n",
                "    if 'recipient' in df.columns:\n",
                "        circular = df[df[wallet_col] == df['recipient']]\n",
                "        circular_pct = len(circular) / len(swaps) * 100\n",
                "    else:\n",
                "        circular_pct = 0\n",
                "    \n",
                "    # === METRIC 4: K-Means Clustering on volumes ===\n",
                "    volumes = df['amountUSD'].values.reshape(-1, 1)\n",
                "    n_clusters = min(3, len(volumes))  # Don't cluster more than data points\n",
                "    if n_clusters >= 2:\n",
                "        kmeans = KMeans(n_clusters=n_clusters, random_state=42, n_init=10)\n",
                "        clusters = kmeans.fit_predict(volumes)\n",
                "        cluster_sizes = pd.Series(clusters).value_counts()\n",
                "        dominant_cluster_pct = cluster_sizes.iloc[0] / len(clusters) * 100\n",
                "    else:\n",
                "        dominant_cluster_pct = 100\n",
                "    \n",
                "    # === FINAL SCORE ===\n",
                "    score = (\n",
                "        (top_3_concentration * 0.4) +\n",
                "        ((100 - wallet_ratio) * 0.3) +\n",
                "        (circular_pct * 0.2) +\n",
                "        (dominant_cluster_pct * 0.1)\n",
                "    )\n",
                "    score = min(100, max(0, score))\n",
                "    \n",
                "    # Recommendation\n",
                "    if score >= 70:\n",
                "        recommendation = \"BLOCK - High wash trading probability\"\n",
                "        is_risky = True\n",
                "    elif score >= 50:\n",
                "        recommendation = \"CAUTION - Moderate concentration\"\n",
                "        is_risky = False\n",
                "    else:\n",
                "        recommendation = \"SAFE - Organic trading patterns\"\n",
                "        is_risky = False\n",
                "    \n",
                "    return {\n",
                "        \"pool_address\": pool_address,\n",
                "        \"analysis_date\": datetime.now().isoformat(),\n",
                "        \"swaps_analyzed\": len(swaps),\n",
                "        \"unique_wallets\": unique_wallets,\n",
                "        \"metrics\": {\n",
                "            \"top_3_wallet_concentration\": round(top_3_concentration, 2),\n",
                "            \"unique_wallet_ratio\": round(wallet_ratio, 2),\n",
                "            \"circular_trading_pct\": round(circular_pct, 2),\n",
                "            \"dominant_cluster_pct\": round(dominant_cluster_pct, 2)\n",
                "        },\n",
                "        \"wash_trading_score\": round(score, 2),\n",
                "        \"is_risky\": is_risky,\n",
                "        \"recommendation\": recommendation\n",
                "    }\n",
                "\n",
                "# ðŸ§ª TEST - Try these known active pools on Base:\n",
                "# Uniswap V3 WETH-USDC: 0x88A43bbDF9D098eEC7bCEda4e2494615dFd9bB9C\n",
                "# Uniswap V3 cbETH-WETH: 0x10648BA41B8565907Cfa1496765fA4D95390aa0d\n",
                "\n",
                "pool = \"0x88A43bbDF9D098eEC7bCEda4e2494615dFd9bB9C\"  # WETH-USDC Uniswap V3\n",
                "result = detect_wash_trading(pool)\n",
                "print(json.dumps(result, indent=2))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## ðŸ’° Module 3: Parking Threshold Optimization\n",
                "\n",
                "**Monte Carlo simulation** to find optimal parking threshold:\n",
                "- Tests different thresholds ($1k, $5k, $10k, $25k)\n",
                "- Considers gas costs and Aave yield\n",
                "- Returns optimal threshold for your capital size"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def optimize_parking_threshold(\n",
                "    capital_usd: float = 50000,\n",
                "    gas_cost_usd: float = 11,\n",
                "    aave_apy: float = 3.5,\n",
                "    avg_pool_apy: float = 15.0,\n",
                "    pool_entry_rate: float = 0.6,\n",
                "    simulation_days: int = 30,\n",
                "    num_simulations: int = 1000\n",
                ") -> dict:\n",
                "    \"\"\"\n",
                "    Monte Carlo simulation to find optimal parking threshold.\n",
                "    \"\"\"\n",
                "    thresholds = [1000, 5000, 10000, 25000, 50000]\n",
                "    results = {}\n",
                "    \n",
                "    for threshold in thresholds:\n",
                "        if threshold > capital_usd:\n",
                "            continue\n",
                "            \n",
                "        total_returns = []\n",
                "        \n",
                "        for _ in range(num_simulations):\n",
                "            balance = capital_usd\n",
                "            parked = 0\n",
                "            days_idle = 0\n",
                "            total_gas = 0\n",
                "            \n",
                "            for day in range(simulation_days):\n",
                "                found_pool = np.random.random() < pool_entry_rate\n",
                "                \n",
                "                if found_pool and balance >= 100:\n",
                "                    if parked > 0:\n",
                "                        balance += parked\n",
                "                        parked = 0\n",
                "                        total_gas += gas_cost_usd\n",
                "                    \n",
                "                    daily_yield = balance * (avg_pool_apy / 100 / 365)\n",
                "                    balance += daily_yield\n",
                "                    total_gas += gas_cost_usd\n",
                "                    days_idle = 0\n",
                "                else:\n",
                "                    days_idle += 1\n",
                "                    \n",
                "                    if days_idle >= 1 and balance >= threshold and parked == 0:\n",
                "                        parked = balance\n",
                "                        balance = 0\n",
                "                        total_gas += gas_cost_usd\n",
                "                    \n",
                "                    if parked > 0:\n",
                "                        daily_aave = parked * (aave_apy / 100 / 365)\n",
                "                        parked += daily_aave\n",
                "            \n",
                "            final = balance + parked - total_gas\n",
                "            total_returns.append(final)\n",
                "        \n",
                "        avg_return = np.mean(total_returns)\n",
                "        std_return = np.std(total_returns)\n",
                "        roi = ((avg_return - capital_usd) / capital_usd) * 100\n",
                "        \n",
                "        results[threshold] = {\n",
                "            \"avg_final_balance\": round(avg_return, 2),\n",
                "            \"std_deviation\": round(std_return, 2),\n",
                "            \"roi_pct\": round(roi, 2),\n",
                "            \"sharpe_ratio\": round(roi / (std_return / capital_usd * 100), 2) if std_return > 0 else 0\n",
                "        }\n",
                "    \n",
                "    optimal = max(results.keys(), key=lambda k: results[k]['sharpe_ratio'])\n",
                "    \n",
                "    return {\n",
                "        \"simulation_params\": {\n",
                "            \"capital_usd\": capital_usd,\n",
                "            \"gas_cost_usd\": gas_cost_usd,\n",
                "            \"aave_apy\": aave_apy,\n",
                "            \"avg_pool_apy\": avg_pool_apy,\n",
                "            \"pool_entry_rate\": pool_entry_rate,\n",
                "            \"simulation_days\": simulation_days,\n",
                "            \"num_simulations\": num_simulations\n",
                "        },\n",
                "        \"threshold_results\": results,\n",
                "        \"optimal_threshold\": optimal,\n",
                "        \"optimal_roi\": results[optimal]['roi_pct'],\n",
                "        \"recommendation\": f\"Set MIN_PARKING_AMOUNT_USD = {optimal}\"\n",
                "    }\n",
                "\n",
                "# ðŸ§ª TEST - Optimize for your capital\n",
                "result = optimize_parking_threshold(capital_usd=50000, gas_cost_usd=11)\n",
                "print(json.dumps(result, indent=2))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## ðŸ“¤ Export Results for Claude\n",
                "\n",
                "Run this cell to generate JSON that you paste into Claude's prompt."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def generate_claude_report(\n",
                "    pools_to_analyze: list = None,\n",
                "    capital: float = 50000\n",
                ") -> str:\n",
                "    report = {\n",
                "        \"generated_at\": datetime.now().isoformat(),\n",
                "        \"source\": \"Google Colab Analytics\",\n",
                "        \"modules\": {}\n",
                "    }\n",
                "    \n",
                "    if pools_to_analyze:\n",
                "        report[\"modules\"][\"apy_trends\"] = []\n",
                "        for pool_id in pools_to_analyze:\n",
                "            trend = analyze_apy_trend(pool_id)\n",
                "            report[\"modules\"][\"apy_trends\"].append(trend)\n",
                "    \n",
                "    report[\"modules\"][\"parking_optimization\"] = optimize_parking_threshold(capital_usd=capital)\n",
                "    \n",
                "    parking = report[\"modules\"][\"parking_optimization\"]\n",
                "    report[\"claude_instructions\"] = f\"\"\"\n",
                "Based on Monte Carlo simulation ({parking['simulation_params']['num_simulations']} runs):\n",
                "- Optimal parking threshold: ${parking['optimal_threshold']:,}\n",
                "- Expected ROI: {parking['optimal_roi']}%\n",
                "\n",
                "ACTION: Update MIN_PARKING_AMOUNT_USD to {parking['optimal_threshold']}\n",
                "\"\"\"\n",
                "    \n",
                "    return json.dumps(report, indent=2)\n",
                "\n",
                "# ðŸš€ Generate final report\n",
                "final_report = generate_claude_report(capital=50000)\n",
                "print(final_report)\n",
                "\n",
                "with open('techne_analytics_report.json', 'w') as f:\n",
                "    f.write(final_report)\n",
                "print(\"\\nâœ… Report saved to techne_analytics_report.json\")"
            ]
        }
    ]
}